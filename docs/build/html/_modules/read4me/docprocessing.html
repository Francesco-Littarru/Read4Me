<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>read4me.docprocessing &mdash; Read4Me 1.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="https://unpkg.com/mermaid@10.2.0/dist/mermaid.min.js"></script>
        <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Read4Me
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Telegram Bot</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.telegram_module.html">Main Telegram Bot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.custom_filters.html">Telegram Custom Filters</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.project_config.html">1. Customize the project .ini files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.project_config.html#virtual-environment-venv">2. Virtual environment (venv)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.project_config.html#install-the-project">3. Install the project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.project_config.html#generate-topics-and-models">4. Generate topics and models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.project_config.html#configure-the-bot-with-botfather">5. Configure the bot with BotFather</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.project_config.html#run-the-bot">6. Run the bot</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Modules Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.datafactory.html">Dataset Creation module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.topicsprocessor.html">Process Topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.docprocessing.html">Process Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.userbase.html">Manage users</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.models.html">Retrieve models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Scripts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.scripts.make_corpus.html">Corpus script</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../read4me.scripts.topics.html">Topics script</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Read4Me</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">read4me.docprocessing</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for read4me.docprocessing</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">**What is this module for?**</span>

<span class="sd">This module is for the semantic processing of documents using a list of topic vectors as reference.</span>
<span class="sd">The documents are analyzed at a sentence level.</span>

<span class="sd">**What classes are there?**</span>

<span class="sd">* :class:`Doc` - Document</span>

<span class="sd">**How can you use it?**</span>

<span class="sd">To use the class simply initialize a Doc instance with the document string</span>

<span class="sd">.. code-block::</span>

<span class="sd">    doc = Doc(&quot;The quick brown fox jumps over the lazy dog.&quot;)</span>

<span class="sd">then process the document using the following:</span>

<span class="sd">* A function that takes a string, clean the text and returns a string.</span>
<span class="sd">* A set of Part-of-Speech tags that defines which types of words to keep.</span>
<span class="sd">  (see here for tags: https://universaldependencies.org/u/pos/)</span>
<span class="sd">* Models:</span>

<span class="sd">	* :class:`~gensim.models.keyedvectors.KeyedVectors` compatible Word2Vec model with normalized vectors.</span>
<span class="sd">	* :class:`~gensim.models.tfidfmodel.TfidfModel` and :class:`~gensim.corpora.dictionary.Dictionary` for it.</span>
<span class="sd">	* `Spacy model &lt;https://spacy.io/usage/models/&gt;`_.</span>

<span class="sd">* the topics as numpy arrays, generated with the Word2Vec model.</span>

<span class="sd">.. code-block::</span>

<span class="sd">    doc.process(w2v, tfidf, dct, nlp, pos_set, topics)</span>

<span class="sd">After the processing, some of the info you can get from the doc instance are:</span>

<span class="sd">* The number of sentences :attr:`~Doc.num_sentences`.</span>
<span class="sd">* Most frequent topics :attr:`~Doc.topic_counts`.</span>
<span class="sd">* Most similar sentence to a specific topic :meth:`~Doc.excerpt`.</span>
<span class="sd">* The :attr:`~Doc.similarity_matrix` mapping each sentence to each topic with the similarity score.</span>
<span class="sd">* A :attr:`~Doc.vector` (numpy array) that represents the embedded document as coefficients of the topics.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Self</span><span class="p">,</span> <span class="n">Callable</span>

<span class="kn">from</span> <span class="nn">ftlangdetect</span> <span class="kn">import</span> <span class="n">detect</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span><span class="p">,</span> <span class="n">TfidfModel</span>
<span class="kn">from</span> <span class="nn">gensim.corpora</span> <span class="kn">import</span> <span class="n">Dictionary</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">numpy.typing</span> <span class="kn">import</span> <span class="n">NDArray</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">__MAX_SENTENCE_LEN__</span> <span class="o">=</span> <span class="mi">4096</span>


<div class="viewcode-block" id="Doc"><a class="viewcode-back" href="../../read4me.docprocessing.html#read4me.docprocessing.Doc">[docs]</a><span class="k">class</span> <span class="nc">Doc</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An instance of this class contains information about the semantic relationship between a document and</span>
<span class="sd">    a list of topics.</span>

<span class="sd">    The following are required to process an instance:</span>

<span class="sd">    * Word2vec model compatible with gensim&#39;s :class:`~gensim.models.keyedvectors.KeyedVectors`.</span>
<span class="sd">    * List of topics that belong to the same vector space of the word2vec model, as a list of numpy arrays.</span>
<span class="sd">    * Tfidf model generated with gensim&#39;s :class:`~gensim.models.tfidfmodel.TfidfModel`.</span>
<span class="sd">    * Dictionary for the tfidf model, generated with gensim&#39;s :class:`~gensim.corpora.dictionary.Dictionary`.</span>
<span class="sd">    * Spacy model for the english language.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">doc</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize a new instance with a document.</span>

<span class="sd">        :param doc: Document as a string.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__doc</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">doc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__sentence_coordinates</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># list of offset and length values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__processed</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__similarity_matrix</span><span class="p">:</span> <span class="n">NDArray</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># dimensions: sentences x topics, value: similarity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__doc_topics</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>  <span class="c1"># topic_id: list most similar sents</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__topic_counts</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__similarity_fallback</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="Doc.process"><a class="viewcode-back" href="../../read4me.docprocessing.html#read4me.docprocessing.Doc.process">[docs]</a>    <span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">w2v</span><span class="p">:</span> <span class="n">KeyedVectors</span><span class="p">,</span> <span class="n">tfidf</span><span class="p">:</span> <span class="n">TfidfModel</span><span class="p">,</span> <span class="n">dct</span><span class="p">:</span> <span class="n">Dictionary</span><span class="p">,</span> <span class="n">nlp</span><span class="p">:</span> <span class="n">spacy</span><span class="o">.</span><span class="n">Language</span><span class="p">,</span>
                <span class="n">pos_set</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
                <span class="n">topics</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
                <span class="n">text_cleaner</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">txt</span><span class="p">:</span> <span class="n">txt</span><span class="p">,</span>
                <span class="n">min_similarity</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                <span class="n">topics_per_sentence</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Process the document.</span>

<span class="sd">        The steps are the following:</span>

<span class="sd">        #. The text is segmented in sentences, cleaned and normalized.</span>
<span class="sd">        #. The sentences are embedded in centroid vectors, using word2vec and tfidf models.</span>
<span class="sd">        #. The two matrices of centroids and topic vectors are multiplied, obtaining the matrix of similarities.</span>
<span class="sd">           The shape of the matrix is given by the number of sentences and the number of topics.</span>
<span class="sd">        #. Selection of the most frequent topics document-wise, by first mapping a fixed number of most similar topics</span>
<span class="sd">           for each sentence and then counting the most frequent topics from this mapping.</span>

<span class="sd">        :param w2v: Word2vec :class:`~gensim.models.keyedvectors.KeyedVectors` model.</span>
<span class="sd">        :param tfidf: :class:`~gensim.models.tfidfmodel.TfidfModel` model.</span>
<span class="sd">        :param dct: :class:`~gensim.corpora.dictionary.Dictionary` for the tfidf model.</span>
<span class="sd">        :param nlp: Spacy language model, loaded with `spacy.load() &lt;https://spacy.io/usage/models/&gt;`_.</span>
<span class="sd">        :param pos_set: A set of Part-of-Speech strings. See https://universaldependencies.org/u/pos/.</span>
<span class="sd">        :param topics: Topic vectors.</span>
<span class="sd">        :param text_cleaner: Cleaning function, any function that takes a string as an argument and returns a string.</span>
<span class="sd">        :param min_similarity: Similarity threshold for the mapping of topics with sentences.</span>
<span class="sd">        :param topics_per_sentence: Maximum number of topics that should be mapped to each sentence above the similarity</span>
<span class="sd">               threshold.</span>
<span class="sd">        :return: None if the document is not in english, otherwise return the instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__doc</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">detect</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\n&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">doc</span><span class="o">.</span><span class="n">text</span><span class="p">))[</span><span class="s1">&#39;lang&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;en&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="c1"># 1) cleaning and normalization</span>
        <span class="n">idx_doc</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">sents</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__sentence_coordinates</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">sent</span><span class="o">.</span><span class="n">start_char</span><span class="p">,</span> <span class="n">sent</span><span class="o">.</span><span class="n">end_char</span><span class="p">))</span>
            <span class="n">sent_</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">w</span><span class="o">.</span><span class="n">lemma_</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sent</span> <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">pos_</span> <span class="ow">in</span> <span class="n">pos_set</span><span class="p">])</span>
            <span class="n">sent_</span> <span class="o">=</span> <span class="n">text_cleaner</span><span class="p">(</span><span class="n">sent_</span><span class="p">)</span>
            <span class="n">idx_sent</span> <span class="o">=</span> <span class="n">dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">sent_</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span>  <span class="c1"># OOV words are removed here.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx_sent</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">idx_doc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx_sent</span><span class="p">)</span>
        <span class="n">doc_tfidf</span> <span class="o">=</span> <span class="n">tfidf</span><span class="p">[</span><span class="n">idx_doc</span><span class="p">]</span>

        <span class="c1"># 2) semantic embedding</span>
        <span class="n">centroids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">NDArray</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">sent_tfidf</span> <span class="ow">in</span> <span class="n">doc_tfidf</span><span class="p">:</span>
            <span class="n">centroid</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="p">[</span><span class="n">w2v</span><span class="p">[</span><span class="n">dct</span><span class="p">[</span><span class="n">word_id</span><span class="p">]]</span> <span class="o">*</span> <span class="n">value</span> <span class="k">for</span> <span class="p">(</span><span class="n">word_id</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">sent_tfidf</span>
                 <span class="k">if</span> <span class="n">word_id</span> <span class="ow">in</span> <span class="n">dct</span> <span class="ow">and</span> <span class="n">dct</span><span class="p">[</span><span class="n">word_id</span><span class="p">]</span> <span class="ow">in</span> <span class="n">w2v</span><span class="o">.</span><span class="n">key_to_index</span><span class="p">],</span>
                <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">centroid</span><span class="o">.</span><span class="vm">__class__</span> <span class="ow">is</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
                <span class="n">centroid</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w2v</span><span class="o">.</span><span class="n">vector_size</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">centroid</span> <span class="o">=</span> <span class="n">centroid</span> <span class="o">/</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">centroid</span><span class="p">)</span>
            <span class="n">centroids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">centroid</span><span class="p">)</span>

        <span class="c1"># 3) matrix multiplication</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__similarity_matrix</span><span class="p">:</span> <span class="n">NDArray</span> <span class="o">=</span> <span class="n">centroids</span> <span class="o">@</span> <span class="n">numpy</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">topics</span><span class="p">)</span>

        <span class="c1"># 4) similarity mapping and selection</span>
        <span class="k">if</span> <span class="n">topics</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">topics_per_sentence</span><span class="p">:</span>
            <span class="n">topics_per_sentence</span> <span class="o">=</span> <span class="n">topics</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__map_topics_to_sentences</span><span class="p">(</span><span class="n">topics_per_sentence</span><span class="p">,</span> <span class="n">min_similarity</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__set_topic_counts</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__processed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="Doc.num_sentences"><a class="viewcode-back" href="../../read4me.docprocessing.html#read4me.docprocessing.Doc.num_sentences">[docs]</a>    <span class="k">def</span> <span class="nf">num_sentences</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the number of sentences in the document.</span>

<span class="sd">        :return: Number of sentences.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__sentence_coordinates</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">processed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get True if the document has been processed, False otherwise.</span>

<span class="sd">        :return: Boolean flag.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__processed</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">topic_counts</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the dict of topic counts in the document.</span>

<span class="sd">        Each key is a topic id, each value is the number of sentences found to be correlated to that topic.</span>
<span class="sd">        Each sentence has a maximum number of topics correlated to it, defined as parameter in :meth:`~Doc.process`.</span>

<span class="sd">        :return: dict of counts.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__topic_counts</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">has_triggered_fallback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get True if the similarity between topics and sentences has never reached the minimum value set for processing.</span>

<span class="sd">        :return: Boolean flag.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__similarity_fallback</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">similarity_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the similarity matrix.</span>

<span class="sd">        :return: NDArray after processing the document, None otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__similarity_matrix</span>

<div class="viewcode-block" id="Doc.sentence"><a class="viewcode-back" href="../../read4me.docprocessing.html#read4me.docprocessing.Doc.sentence">[docs]</a>    <span class="k">def</span> <span class="nf">sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pos_sent</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the sentence at position pos_sent from the original text.</span>
<span class="sd">        If the sentence is longer than the maximum allowed, return the sentence truncated.</span>

<span class="sd">        :param pos_sent: Sentence position in the text, starting from 0.</span>
<span class="sd">        :return: Sentence as a string, None if the document has not been processed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">processed</span><span class="p">:</span>
            <span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__sentence_coordinates</span><span class="p">[</span><span class="n">pos_sent</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span> <span class="o">&gt;</span> <span class="n">__MAX_SENTENCE_LEN__</span><span class="p">:</span>  <span class="c1"># length failsafe</span>
                <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">__MAX_SENTENCE_LEN__</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__doc</span><span class="p">[</span><span class="n">start</span><span class="p">:</span> <span class="n">end</span><span class="p">]</span>
        <span class="k">return</span> <span class="kc">None</span></div>

    <span class="k">def</span> <span class="nf">__set_topic_counts</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">topn</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Populate a dict with the topn most frequent topics in the text, along with their counts.</span>

<span class="sd">        :param topn: Maximum number of topics to use.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">highest_counts</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([(</span><span class="n">t_id</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__doc_topics</span><span class="p">[</span><span class="n">t_id</span><span class="p">]))</span> <span class="k">for</span> <span class="n">t_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__doc_topics</span><span class="o">.</span><span class="n">keys</span><span class="p">()],</span>
                                <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">topn</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__topic_counts</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">highest_counts</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__map_topics_to_sentences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">topics_per_sentence</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">min_similarity</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.60</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Select the most frequent topics document-wise, by first mapping a fixed number of most similar topics</span>
<span class="sd">        for each sentence and then counting the most frequent topics from this mapping.</span>

<span class="sd">        :param topics_per_sentence: Value to limit the number of topics linked to each sentence.</span>
<span class="sd">        :param min_similarity: Minimum similarity value.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence_similarities</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__similarity_matrix</span><span class="p">):</span>  <span class="c1"># dimensions: sentences x topics</span>
            <span class="c1"># select the indexes (default 2) of the topics with the highest similarity to the i-th sentence</span>
            <span class="n">tops</span> <span class="o">=</span> <span class="p">[</span><span class="o">*</span><span class="nb">reversed</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">sentence_similarities</span><span class="p">)[</span><span class="o">-</span><span class="n">topics_per_sentence</span><span class="p">:])]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">topics_per_sentence</span><span class="p">):</span>
                <span class="c1"># if the values exceed min_similarity, append the sentence_id and the value to the entry of the topic.</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">tops</span><span class="p">[</span><span class="n">j</span><span class="p">]]</span> <span class="o">&gt;=</span> <span class="n">min_similarity</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__doc_topics</span><span class="p">[</span><span class="n">tops</span><span class="p">[</span><span class="n">j</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">tops</span><span class="p">[</span><span class="n">j</span><span class="p">]]))</span>

        <span class="c1"># strategy for when the minimum similarity value is never met, trigger similarity fallback.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">__doc_topics</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__similarity_fallback</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence_similarities</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__similarity_matrix</span><span class="p">):</span>
                <span class="n">max_sim_topic</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">sentence_similarities</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__doc_topics</span><span class="p">[</span><span class="n">max_sim_topic</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">max_sim_topic</span><span class="p">]))</span>

<div class="viewcode-block" id="Doc.excerpt"><a class="viewcode-back" href="../../read4me.docprocessing.html#read4me.docprocessing.Doc.excerpt">[docs]</a>    <span class="k">def</span> <span class="nf">excerpt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">topic_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a topic id, get the most similar sentence to it.</span>

<span class="sd">        :param topic_id: Id of the topic, starting from 0.</span>
<span class="sd">        :return: Sentence as a string.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sentence</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">most_similar_sentence_id</span><span class="p">(</span><span class="n">topic_id</span><span class="p">))</span></div>

<div class="viewcode-block" id="Doc.most_similar_sentence_id"><a class="viewcode-back" href="../../read4me.docprocessing.html#read4me.docprocessing.Doc.most_similar_sentence_id">[docs]</a>    <span class="k">def</span> <span class="nf">most_similar_sentence_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">topic_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a topic id, get the id of the most similar sentence to it.</span>

<span class="sd">        :param topic_id: Id of the topic, starting from 0.</span>
<span class="sd">        :return: Sentence id.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__similarity_matrix</span><span class="p">[:,</span> <span class="n">topic_id</span><span class="p">]))</span></div>

<div class="viewcode-block" id="Doc.vector"><a class="viewcode-back" href="../../read4me.docprocessing.html#read4me.docprocessing.Doc.vector">[docs]</a>    <span class="k">def</span> <span class="nf">vector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a normalized vector of the document, mapping dimensions to topics.</span>
<span class="sd">        The number of dimensions in the vector is equal to the number of topics.</span>

<span class="sd">        :return: Numpy NDArray vector.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">topic_counts</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">processed</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="n">vec</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__similarity_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">counts</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">vec</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="n">vec</span> <span class="o">=</span> <span class="n">vec</span> <span class="o">/</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">vec</span></div></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Francesco Littarru.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>